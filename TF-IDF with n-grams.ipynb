{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6096e428",
   "metadata": {},
   "source": [
    "------------------\n",
    " ## Suicide Sentiment Analysis Project \n",
    " - Using TF-IDF As Feature Extraction\n",
    " - Using Some Classification models As RandomForest, LinearSVC, MultinomialNB\n",
    " - Using Some Preprocessing as Lemmatization, Removing Stop Words\n",
    " - Finally,  The best Results in this notebook is 91%.\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9929ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa6f9",
   "metadata": {},
   "source": [
    "## Read Suicide_Detection File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a536b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Suicide = pd.read_csv('Suicide_Detection.csv')\n",
    "data_split = np.array_split(Suicide, 20)\n",
    "Suicide = data_split[0]\n",
    "Suicide = Suicide.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e8fb1",
   "metadata": {},
   "source": [
    "## Preparing For Stopword removal and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823cae3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/saied/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c51c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Suicide.drop('class', axis=1)\n",
    "y = Suicide['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425ee57",
   "metadata": {},
   "source": [
    "# Text Pre Proceessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecdcca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove emails\n",
    "email_regex = r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n",
    "regexes_to_remove = [email_regex, r'Subject:', r'Re:']\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    # removing all special charachter\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(X['text'][i]))\n",
    "    # make document as lowerCase\n",
    "    review = review.lower()\n",
    "    # splitting the documents into words for ex ['iam', 'omar']\n",
    "    review = review.split()\n",
    "    # make limmatization --> (change, changing, changes)---> (change)\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "    # join the document agian\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    # removing mails\n",
    "    for r in regexes_to_remove:\n",
    "        X['text'][i] = re.sub(r, '', review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a21d38",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990ade7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82774d0",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96b1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_n1 = TfidfVectorizer(max_features=10000)\n",
    "tfidf_vectorizer_n2 = TfidfVectorizer(max_features=10000, ngram_range=(2,2))\n",
    "tfidf_vectorizer_n12 = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "tfidf_vectorizer_n3 = TfidfVectorizer(max_features=10000, ngram_range=(3,3))\n",
    "tfidf_vectorizer_n123 = TfidfVectorizer(max_features=10000, ngram_range=(1,3))\n",
    "\n",
    "X_tfidf_train_n1 = tfidf_vectorizer_n1.fit_transform(X_train['text'])\n",
    "X_tfidf_test_n1 = tfidf_vectorizer_n1.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_train_n2 = tfidf_vectorizer_n2.fit_transform(X_train['text'])\n",
    "X_tfidf_test_n2 = tfidf_vectorizer_n2.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_train_n12 = tfidf_vectorizer_n12.fit_transform(X_train['text'])\n",
    "X_tfidf_test_n12 = tfidf_vectorizer_n12.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_train_n3 = tfidf_vectorizer_n3.fit_transform(X_train['text'])\n",
    "X_tfidf_test_n3 = tfidf_vectorizer_n3.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_train_n123 = tfidf_vectorizer_n123.fit_transform(X_train['text'])\n",
    "X_tfidf_test_n123 = tfidf_vectorizer_n123.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_train_list = [X_tfidf_train_n1, X_tfidf_train_n2, X_tfidf_train_n3, X_tfidf_train_n12,X_tfidf_train_n123]\n",
    "X_tfidf_test_list = [X_tfidf_test_n1, X_tfidf_test_n2, X_tfidf_test_n3, X_tfidf_test_n12,X_tfidf_test_n123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba96c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8122, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf_train_n1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211a79c",
   "metadata": {},
   "source": [
    "---------------\n",
    "- As we see the no. of features very large so we need to make feature selection and feature scaling\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1805bd",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5d1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_norm_list = []\n",
    "X_test_norm_list = []\n",
    "\n",
    "# function to fit data(calculate the min and max) then transform data to it\n",
    "for X_tfidf_train, X_tfidf_test in zip(X_tfidf_train_list, X_tfidf_test_list):\n",
    "    X_norm_list.append(X_tfidf_train.toarray())\n",
    "    X_test_norm_list.append(X_tfidf_test.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f95eb1",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "091e6574",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_norm_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# We Can select any model but linearSVC has l1 norm penality which deals with sparse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m lsvc \u001b[38;5;241m=\u001b[39m LinearSVC(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, dual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_norm,X_test_norm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mX_norm_list\u001b[49m, X_test_norm_list):\n\u001b[1;32m     10\u001b[0m     lsvc\u001b[38;5;241m.\u001b[39mfit(X_norm, y_train)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# This function select the best features that has high weigh\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_norm_list' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X_selection_list = []\n",
    "X_test_selection_list = []\n",
    "# We Can select any model but linearSVC has l1 norm penality which deals with sparse\n",
    "lsvc = LinearSVC(C=100, penalty='l1', max_iter=500, dual=False)\n",
    "\n",
    "for X_norm,X_test_norm in zip(X_norm_list, X_test_norm_list):\n",
    "    lsvc.fit(X_norm, y_train)\n",
    "\n",
    "    # This function select the best features that has high weigh\n",
    "    fs = SelectFromModel(lsvc, prefit=True)\n",
    "    # This function redeuce X to the selected features\n",
    "    X_selection_list.append(fs.transform(X_norm))\n",
    "    X_test_selection_list.append(fs.transform(X_test_norm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8ed63",
   "metadata": {},
   "source": [
    "##  Using LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ef5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "grams = [1,2,3,12,123]\n",
    "for X_selection,X_test_selection,i in zip(X_selection_list, X_test_selection_list,grams):\n",
    "    lsvc.fit(X_selection, y_train)\n",
    "    y_predict_1 = lsvc.predict(X_test_selection)\n",
    "    print(i,\"-gram\\n\",metrics.classification_report(y_test, y_predict_1, target_names=['Suicide', 'Non-Suicide']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7054d",
   "metadata": {},
   "source": [
    "## Using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1887aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_selection,X_test_selection,i in zip(X_selection_list, X_test_selection_list,grams):\n",
    "    clf = RandomForestClassifier(max_depth=10)\n",
    "    clf.fit(X_selection, y_train)\n",
    "    y_predict_2 = clf.predict(X_test_selection)\n",
    "    print(i,\"-gram\\n\",metrics.classification_report(y_test, y_predict_2, target_names=['Suicide', 'Non-Suicide']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f7392",
   "metadata": {},
   "source": [
    "## Using Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "460116e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.94      0.81      0.87      1773\n",
      " Non-Suicide       0.83      0.95      0.88      1709\n",
      "\n",
      "    accuracy                           0.88      3482\n",
      "   macro avg       0.88      0.88      0.88      3482\n",
      "weighted avg       0.88      0.88      0.88      3482\n",
      "\n",
      "2 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.85      0.82      0.84      1773\n",
      " Non-Suicide       0.82      0.85      0.84      1709\n",
      "\n",
      "    accuracy                           0.84      3482\n",
      "   macro avg       0.84      0.84      0.84      3482\n",
      "weighted avg       0.84      0.84      0.84      3482\n",
      "\n",
      "3 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.68      0.92      0.79      1773\n",
      " Non-Suicide       0.88      0.56      0.68      1709\n",
      "\n",
      "    accuracy                           0.74      3482\n",
      "   macro avg       0.78      0.74      0.73      3482\n",
      "weighted avg       0.78      0.74      0.73      3482\n",
      "\n",
      "12 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.94      0.84      0.88      1773\n",
      " Non-Suicide       0.85      0.94      0.89      1709\n",
      "\n",
      "    accuracy                           0.89      3482\n",
      "   macro avg       0.89      0.89      0.89      3482\n",
      "weighted avg       0.89      0.89      0.89      3482\n",
      "\n",
      "123 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.93      0.85      0.89      1773\n",
      " Non-Suicide       0.85      0.94      0.89      1709\n",
      "\n",
      "    accuracy                           0.89      3482\n",
      "   macro avg       0.89      0.89      0.89      3482\n",
      "weighted avg       0.89      0.89      0.89      3482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_selection,X_test_selection,i in zip(X_selection_list, X_test_selection_list,grams):\n",
    "    mb = MultinomialNB()\n",
    "    mb.fit(X_selection, y_train)\n",
    "    y_predict_3 = mb.predict(X_test_selection)\n",
    "    print(i,\"-gram\\n\",metrics.classification_report(y_test, y_predict_3, target_names=['Suicide', 'Non-Suicide']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd178f",
   "metadata": {},
   "source": [
    "## Using Ensamble Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be3f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,  SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e56b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\")\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True)\n",
    "mb = MultinomialNB()\n",
    "sgd = SGDClassifier(alpha=.0001, max_iter=50, loss='log',\n",
    "                                       penalty=\"elasticnet\", n_jobs=-1)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('mb', mb),('sgd', sgd)],\n",
    "voting='soft')\n",
    "#voting_clf.fit(X_selection, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc68bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.91      0.92      0.92      1753\n",
      " Non-Suicide       0.92      0.91      0.91      1729\n",
      "\n",
      "    accuracy                           0.91      3482\n",
      "   macro avg       0.92      0.91      0.91      3482\n",
      "weighted avg       0.92      0.91      0.91      3482\n",
      "\n",
      "2 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.82      0.85      0.84      1753\n",
      " Non-Suicide       0.84      0.82      0.83      1729\n",
      "\n",
      "    accuracy                           0.83      3482\n",
      "   macro avg       0.83      0.83      0.83      3482\n",
      "weighted avg       0.83      0.83      0.83      3482\n",
      "\n",
      "3 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.69      0.92      0.78      1753\n",
      " Non-Suicide       0.87      0.58      0.69      1729\n",
      "\n",
      "    accuracy                           0.75      3482\n",
      "   macro avg       0.78      0.75      0.74      3482\n",
      "weighted avg       0.78      0.75      0.74      3482\n",
      "\n",
      "12 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.91      0.91      0.91      1753\n",
      " Non-Suicide       0.91      0.91      0.91      1729\n",
      "\n",
      "    accuracy                           0.91      3482\n",
      "   macro avg       0.91      0.91      0.91      3482\n",
      "weighted avg       0.91      0.91      0.91      3482\n",
      "\n",
      "123 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.91      0.92      0.91      1753\n",
      " Non-Suicide       0.91      0.91      0.91      1729\n",
      "\n",
      "    accuracy                           0.91      3482\n",
      "   macro avg       0.91      0.91      0.91      3482\n",
      "weighted avg       0.91      0.91      0.91      3482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_selection,X_test_selection,i in zip(X_selection_list, X_test_selection_list,grams):\n",
    "    voting_clf.fit(X_selection, y_train)\n",
    "    y_predict_4 = voting_clf.predict(X_test_selection)\n",
    "    print(i,\"-gram\\n\",metrics.classification_report(y_test, y_predict_4, target_names=['Suicide', 'Non-Suicide']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c852a54",
   "metadata": {},
   "source": [
    "## Using Bagging Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc5a9271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.82      0.89      0.85      1773\n",
      " Non-Suicide       0.88      0.79      0.83      1709\n",
      "\n",
      "    accuracy                           0.84      3482\n",
      "   macro avg       0.85      0.84      0.84      3482\n",
      "weighted avg       0.85      0.84      0.84      3482\n",
      "\n",
      "2 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.60      0.96      0.74      1773\n",
      " Non-Suicide       0.89      0.34      0.49      1709\n",
      "\n",
      "    accuracy                           0.65      3482\n",
      "   macro avg       0.75      0.65      0.61      3482\n",
      "weighted avg       0.74      0.65      0.62      3482\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\nouran\\programs\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.51      1.00      0.67      1773\n",
      " Non-Suicide       0.00      0.00      0.00      1709\n",
      "\n",
      "    accuracy                           0.51      3482\n",
      "   macro avg       0.25      0.50      0.34      3482\n",
      "weighted avg       0.26      0.51      0.34      3482\n",
      "\n",
      "12 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.82      0.89      0.85      1773\n",
      " Non-Suicide       0.88      0.79      0.83      1709\n",
      "\n",
      "    accuracy                           0.84      3482\n",
      "   macro avg       0.85      0.84      0.84      3482\n",
      "weighted avg       0.85      0.84      0.84      3482\n",
      "\n",
      "123 -gram\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Suicide       0.82      0.89      0.85      1773\n",
      " Non-Suicide       0.87      0.79      0.83      1709\n",
      "\n",
      "    accuracy                           0.84      3482\n",
      "   macro avg       0.84      0.84      0.84      3482\n",
      "weighted avg       0.84      0.84      0.84      3482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bag_clf = BaggingClassifier(\n",
    "DecisionTreeClassifier(), n_estimators=500,\n",
    "max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "for X_selection,X_test_selection,i in zip(X_selection_list, X_test_selection_list,grams):\n",
    "    bag_clf.fit(X_selection, y_train)\n",
    "    y_pred_5 = bag_clf.predict(X_test_selection)\n",
    "    print(i,\"-gram\\n\",metrics.classification_report(y_test, y_pred_5, target_names=['Suicide', 'Non-Suicide']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
